{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-FlkWhyKNPz3"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/PythonBeginners/Meetup034_StartML/blob/main/\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zn0i0TXKNP0A"
   },
   "source": [
    "#### 参考URL\n",
    "https://qiita.com/fukuit/items/215ef75113d97560e599"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JGhMJW6FNP0B"
   },
   "source": [
    "#### PyTorchのインストールについて\n",
    "- Google Colabにはデフォルトでpytorchが入っているので、pipで入れる必要はありません"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7emk3AXYNP0C"
   },
   "outputs": [],
   "source": [
    "# !pip install -U torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXDpMjMaNP0D"
   },
   "source": [
    "#### ライブラリのimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bUCO0tjlNP0E",
    "outputId": "67605a2c-a95a-4c7e-e58b-5c8fc5c622be"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "IvoleHkQNP0J",
    "outputId": "3f0e2ec3-50bc-41fa-b930-bcb08d1e8d71"
   },
   "outputs": [],
   "source": [
    "# GPU(CUDA)が使えるときはGPUを使う\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YfUcOARrNP0K"
   },
   "source": [
    "#### 標準化\n",
    "[transforms.Compose()](https://pytorch.org/docs/stable/torchvision/transforms.html)によって、MNISTの各ピクセル値を正規分布になるように変換します。\n",
    "以下は公式のリファレンスより抜粋\n",
    "\n",
    "```\n",
    "Normalize a tensor image with mean and standard deviation. Given mean: (M1,...,Mn) and std: (S1,..,Sn) for n channels, this transform will normalize each channel of the input torch.*Tensor i.e. output[channel] = (input[channel] - mean[channel]) / std[channel]\n",
    "```\n",
    "\n",
    "以下のコードではmean=0.5、std=0.5となるように変換するフィルタを定義しています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FrfzttiPNP0L"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, ), (0.5, ))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usvyqTjwNP0L"
   },
   "source": [
    "#### データのダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eiqu3fNzNP0M"
   },
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.MNIST(root='./data', \n",
    "                                        train=True,\n",
    "                                        download=True,\n",
    "                                        transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                            batch_size=100,\n",
    "                                            shuffle=True,\n",
    "                                            num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', \n",
    "                                        train=False, \n",
    "                                        download=True, \n",
    "                                        transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, \n",
    "                                            batch_size=100,\n",
    "                                            shuffle=False, \n",
    "                                            num_workers=2)\n",
    "\n",
    "classes = tuple(np.linspace(0, 9, 10, dtype=np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O64qmfzaNP0M"
   },
   "source": [
    "#### NeuralNetの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-hg-tDXJNP0M"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3) # 28x28x32 -> 26x26x32\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3) # 26x26x64 -> 24x24x64 \n",
    "        self.pool = nn.MaxPool2d(2, 2) # 24x24x64 -> 12x12x64\n",
    "        self.dropout1 = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(12 * 12 * 64, 128)\n",
    "        self.dropout2 = nn.Dropout2d()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.dropout1(x)\n",
    "        x = x.view(-1, 12 * 12 * 64)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wXJHK4xONP0N"
   },
   "outputs": [],
   "source": [
    "net = Net().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_IEy6PvNP0N"
   },
   "source": [
    "#### loss関数と最適化の設定をする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_z0SaeQ6NP0N"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MRZadKAUNP0N",
    "outputId": "61f43c76-6cc5-4eab-f333-662ffcc898dd"
   },
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
    "\n",
    "        # GPUが使える時はGPUにデータを送る\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_acc += (outputs.max(1)[1] == labels).sum().item()\n",
    "\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 100 == 99:\n",
    "            print('[{:d}, {:5d}] loss: {:.3f}'\n",
    "                    .format(epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    avg_train_loss = train_loss / len(trainloader.dataset)\n",
    "    avg_train_acc = train_acc / len(trainloader.dataset)\n",
    "    train_loss_list.append(avg_train_loss)\n",
    "    train_acc_list.append(avg_train_acc)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l9UwEGqQOLN_"
   },
   "outputs": [],
   "source": [
    "import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5S_GJ6VdNP0O",
    "outputId": "fb407f58-52b2-40fe-f928-42f7b5205fa1"
   },
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (inputs, labels) in testloader:\n",
    "\n",
    "        # GPUが使える時はGPUにデータを送る\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = net(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy: {:.2f} %%'.format(100 * float(correct/total)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hF8b5LpqNP0O"
   },
   "source": [
    "# やってみよう！\n",
    "- [x] 画像を可視化してみよう！\n",
    "- [x] 当てられている画像と当てられていない画像をそれぞれ可視化してみよう！\n",
    "    - これはテストデータでやるのが尤もっぽい\n",
    "- [x] precision、recall、f1-scoreを出してみよう！\n",
    "    - classification_report使ったけどﾖｼ!\n",
    "    - presisionは適合率。正と予測したデータのうち，実際に正であるものの割合\n",
    "    - recallは再現率。実際に正であるもののうち，正であると予測されたものの割合。\n",
    "    - f1は適合率と再現率の調和平均。これは1に近いほど良い精度といえる。\n",
    "    - [参考](https://qiita.com/FukuharaYohei/items/be89a99c53586fa4e2e4)\n",
    "- [x] 学習曲線を出してみよう！\n",
    "    - [参考](https://qiita.com/makaishi2/items/3676d216fe9b34b63430)\n",
    "- [ ] validationスコア、testスコアを出してみよう！\n",
    "- [x] cross-validationしてみよう！\n",
    "    - いまの状態だとしてみただけの状態になっている。\n",
    "    - 本来はこれでデータに偏りがないことを調査したりする。\n",
    "    - データに偏りがある場合、つまり学習に偏りがあることになり、正常な学習、精度とは言えなくなってしまう\n",
    "    - 今回の例だと全てにおいて精度が良かったので大丈夫\n",
    "- [ ] あまりにも汚い手書き文字は取り除いて学習してみよう！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A1qI3p_NPeWO",
    "outputId": "8e0b4db0-8cca-4e86-e319-f00d78e9b106"
   },
   "outputs": [],
   "source": [
    "testloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cTDGiEIYQMTv"
   },
   "outputs": [],
   "source": [
    "for i, data in enumerate(testloader):\n",
    "    x, y = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fQLdBUdtRbI5"
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(testset,batch_size=20,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vBYwGC9VS4Ek"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 839
    },
    "id": "FDpCJblRQaZL",
    "outputId": "fb783375-bd8f-4738-b157-84e36e6d8b66"
   },
   "outputs": [],
   "source": [
    "def image_show(data_loader,n, is_correct: bool):\n",
    "\n",
    "  #Augmentationした画像データを読み込む\n",
    "  tmp = iter(data_loader)\n",
    "  images,labels = next(tmp)\n",
    "  outputs = net(images.to(device))\n",
    "  _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "  #n枚の画像を1枚ずつ取り出し、表示する\n",
    "  for i in range(n):\n",
    "    ans = predicted[i] == labels[i]\n",
    "    if ans == is_correct:\n",
    "      #画像をtensorからnumpyに変換\n",
    "      images = images.numpy()\n",
    "      print(\"予測値：\", predicted[i])\n",
    "      print(\"正解値：\", labels[i])\n",
    "      print(predicted[i] == labels[i])\n",
    "\n",
    "      image = np.transpose(images[i],[1,2,0])\n",
    "      plt.imshow(image)\n",
    "      plt.show()\n",
    "\n",
    "  print(classification_report(labels, predicted.detach().cpu().numpy()))\n",
    "    \n",
    "\n",
    "image_show(test_loader,20, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "id": "znyEPl8NarL_",
    "outputId": "14dc72c3-ac86-4e1e-947b-12aec1c0234a"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_acc_list,label='adam', lw=3, c='b')\n",
    "plt.title('accuracy')\n",
    "plt.xticks(size=14)\n",
    "plt.yticks(size=14)\n",
    "plt.grid(lw=2)\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "id": "xpXdMgtCfq2F",
    "outputId": "42672028-fe90-4107-eebb-9661aa5fc14e"
   },
   "outputs": [],
   "source": [
    "# 学習曲線 (損失関数値)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(train_loss_list,label='adam', lw=3, c='b')\n",
    "plt.title('loss')\n",
    "plt.xticks(size=14)\n",
    "plt.yticks(size=14)\n",
    "plt.grid(lw=2)\n",
    "plt.legend(fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DNXzk0b6hs6b",
    "outputId": "d4e5bf47-3384-49ea-bc25-f2a1835cc95d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aupoyFa6f4IK",
    "outputId": "246e291a-7640-4848-9ea3-f06452c80517"
   },
   "outputs": [],
   "source": [
    "# 交差検証(cross varidation)を行ってみる\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data.dataset import Subset\n",
    "\n",
    "\n",
    "dataset = torchvision.datasets.MNIST(root='./data',download=True,transform=transform)\n",
    "\n",
    "batch_size = 16\n",
    "kf = KFold(n_splits=3)\n",
    "\n",
    "nets, accs, losses = [], [], []\n",
    "\n",
    "\n",
    "cv = 0\n",
    "for _fold, (train_index, valid_index) in enumerate(kf.split(dataset)):\n",
    "    train_dataset = Subset(dataset, train_index)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "    valid_dataset   = Subset(dataset, valid_index)\n",
    "    valid_dataloader = DataLoader(valid_dataset, batch_size, shuffle=False)\n",
    "\n",
    "    classes = tuple(np.linspace(0, 9, 10, dtype=np.uint8))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        for i, (inputs, labels) in enumerate(train_dataloader, 0):\n",
    "\n",
    "            # GPUが使える時はGPUにデータを送る\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            train_acc += (outputs.max(1)[1] == labels).sum().item()\n",
    "\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:\n",
    "                print('[{:d}, {:5d}] loss: {:.3f}'\n",
    "                        .format(epoch + 1, i + 1, running_loss / 100))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        avg_train_loss = train_loss / len(trainloader.dataset)\n",
    "        avg_train_acc = train_acc / len(trainloader.dataset)\n",
    "        train_loss_list.append(avg_train_loss)\n",
    "        train_acc_list.append(avg_train_acc)\n",
    "\n",
    "    print('Finished Training')\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for (inputs, labels) in testloader:\n",
    "\n",
    "            # GPUが使える時はGPUにデータを送る\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy: {:.2f} %%'.format(100 * float(correct/total)))\n",
    "\n",
    "    cv += train_loss / kf.n_splits\n",
    "    nets.append(net)\n",
    "    accs.append(correct/total)\n",
    "    losses.append(loss)\n",
    "\n",
    "print(accs)\n",
    "print(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6DfncosEiiC_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
